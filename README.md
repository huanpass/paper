# paper
All the papers below are about machine learning system.

## Pipeline Model Parallelism
PipeDream: Generalized Pipeline Parallelism for DNN Training (SOSP2019) [[Paper]](https://cs.stanford.edu/~matei/papers/2019/sosp_pipedream.pdf)

GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism [[Paper]](https://arxiv.org/pdf/1811.06965.pdf)

Efficient and Robust Parallel DNN Training through Model Parallelism on Multi-GPU Platform [[Paper]](https://arxiv.org/pdf/1809.02839.pdf)

PipeMare: Asynchronous Pipeline Parallel DNN Training [[Paper]](https://arxiv.org/pdf/1910.05124.pdf)

ElasticPipe: An Efficient and Dynamic Model-Parallel Solution to DNN Training [[Paper]](https://dl.acm.org/citation.cfm?id=3331463)

XPipe: Efficient Pipeline Model Parallelism for Multi-GPU DNN Training [[Paper]](https://arxiv.org/pdf/1911.04610.pdf)


## Beyond data and model parallelism
Beyond Data and Model Parallelism for Deep Neural Networks [[Paper]](https://cs.stanford.edu/~zhihao/papers/sysml19a.pdf)

## Communication Schedule
A Generic Communication Scheduler for Distributed DNN Training Acceleration [[Paper]](https://i.cs.hku.hk/~cwu/papers/yhpeng-sosp19.pdf) 


## Resource Schedule
Optimus: An Efficient Dynamic Resource Scheduler for Deep Learning Clusters [[Paper]](https://i.cs.hku.hk/~cwu/papers/yhpeng-eurosys18.pdf)

## Network optimization
Optimizing Network Performance for Distributed DNN Training
on GPU Clusters: ImageNet/AlexNet Training in 1.5 Minutes [[Paper]](https://arxiv.org/pdf/1902.06855.pdf)


